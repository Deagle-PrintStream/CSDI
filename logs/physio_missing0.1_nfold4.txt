02:21:47  Namespace(config='base.yaml', device='cuda:0', seed=1, testmissingratio=0.1, nfold=4, unconditional=False, modelfolder='', nsample=100)
02:21:47  {
    "train": {
        "epochs": 200,
        "batch_size": 16,
        "lr": 0.001
    },
    "diffusion": {
        "layers": 4,
        "channels": 64,
        "nheads": 8,
        "diffusion_embedding_dim": 128,
        "beta_start": 0.0001,
        "beta_end": 0.5,
        "num_steps": 50,
        "schedule": "quad"
    },
    "model": {
        "is_unconditional": false,
        "timeemb": 128,
        "featureemb": 16,
        "target_strategy": "random",
        "test_missing_ratio": 0.1
    }
}
02:21:47  config files saved at /output/physio_fold4_20230719_022147/
02:21:47  dataset loaded with physio_missing 0.1 and seed1
02:25:43  dataset size:3997,training ratio:0.7,        validation ratio:0.10000000000000009,test ratio:0.2,test fold No. 4.
02:25:45  CSDI model with parameters: {'training': True, '_parameters': OrderedDict(), '_buffers': OrderedDict(), '_non_persistent_buffers_set': set(), '_backward_pre_hooks': OrderedDict(), '_backward_hooks': OrderedDict(), '_is_full_backward_hook': None, '_forward_hooks': OrderedDict(), '_forward_hooks_with_kwargs': OrderedDict(), '_forward_pre_hooks': OrderedDict(), '_forward_pre_hooks_with_kwargs': OrderedDict(), '_state_dict_hooks': OrderedDict(), '_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_pre_hooks': OrderedDict(), '_load_state_dict_post_hooks': OrderedDict(), '_modules': OrderedDict([('embed_layer', Embedding(35, 16)), ('diffmodel', diff_CSDI(
  (diffusion_embedding): DiffusionEmbedding(
    (projection1): Linear(in_features=128, out_features=128, bias=True)
    (projection2): Linear(in_features=128, out_features=128, bias=True)
  )
  (input_projection): Conv1d(2, 64, kernel_size=(1,), stride=(1,))
  (output_projection1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
  (output_projection2): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
  (residual_layers): ModuleList(
    (0-3): 4 x ResidualBlock(
      (diffusion_projection): Linear(in_features=128, out_features=64, bias=True)
      (cond_projection): Conv1d(145, 128, kernel_size=(1,), stride=(1,))
      (mid_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (output_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (time_layer): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=64, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (feature_layer): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=64, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=64, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
  )
))]), 'device': 'cuda:0', 'target_dim': 35, 'emb_time_dim': 128, 'emb_feature_dim': 16, 'is_unconditional': False, 'target_strategy': 'random', 'get_mask': <bound method CSDI_base.get_randmask of CSDI_Physio(
  (embed_layer): Embedding(35, 16)
  (diffmodel): diff_CSDI(
    (diffusion_embedding): DiffusionEmbedding(
      (projection1): Linear(in_features=128, out_features=128, bias=True)
      (projection2): Linear(in_features=128, out_features=128, bias=True)
    )
    (input_projection): Conv1d(2, 64, kernel_size=(1,), stride=(1,))
    (output_projection1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))
    (output_projection2): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
    (residual_layers): ModuleList(
      (0-3): 4 x ResidualBlock(
        (diffusion_projection): Linear(in_features=128, out_features=64, bias=True)
        (cond_projection): Conv1d(145, 128, kernel_size=(1,), stride=(1,))
        (mid_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
        (output_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
        (time_layer): TransformerEncoder(
          (layers): ModuleList(
            (0): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
              )
              (linear1): Linear(in_features=64, out_features=64, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=64, out_features=64, bias=True)
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (feature_layer): TransformerEncoder(
          (layers): ModuleList(
            (0): TransformerEncoderLayer(
              (self_attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
              )
              (linear1): Linear(in_features=64, out_features=64, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
              (linear2): Linear(in_features=64, out_features=64, bias=True)
              (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              (dropout1): Dropout(p=0.1, inplace=False)
              (dropout2): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
    )
  )
)>, 'emb_total_dim': 145, 'num_steps': 50, 'beta': array([1.00000000e-04, 5.86931491e-04, 1.47865920e-03, 2.77518314e-03,
       4.47650330e-03, 6.58261967e-03, 9.09353227e-03, 1.20092411e-02,
       1.53297461e-02, 1.90550474e-02, 2.31851449e-02, 2.77200386e-02,
       3.26597285e-02, 3.80042147e-02, 4.37534971e-02, 4.99075757e-02,
       5.64664505e-02, 6.34301215e-02, 7.07985888e-02, 7.85718523e-02,
       8.67499120e-02, 9.53327679e-02, 1.04320420e-01, 1.13712868e-01,
       1.23510113e-01, 1.33712154e-01, 1.44318991e-01, 1.55330624e-01,
       1.66747054e-01, 1.78568279e-01, 1.90794301e-01, 2.03425119e-01,
       2.16460734e-01, 2.29901144e-01, 2.43746351e-01, 2.57996354e-01,
       2.72651153e-01, 2.87710749e-01, 3.03175141e-01, 3.19044329e-01,
       3.35318313e-01, 3.51997093e-01, 3.69080670e-01, 3.86569042e-01,
       4.04462212e-01, 4.22760177e-01, 4.41462938e-01, 4.60570496e-01,
       4.80082850e-01, 5.00000000e-01]), 'alpha_hat': array([0.9999    , 0.99941307, 0.99852134, 0.99722482, 0.9955235 ,
       0.99341738, 0.99090647, 0.98799076, 0.98467025, 0.98094495,
       0.97681486, 0.97227996, 0.96734027, 0.96199579, 0.9562465 ,
       0.95009242, 0.94353355, 0.93656988, 0.92920141, 0.92142815,
       0.91325009, 0.90466723, 0.89567958, 0.88628713, 0.87648989,
       0.86628785, 0.85568101, 0.84466938, 0.83325295, 0.82143172,
       0.8092057 , 0.79657488, 0.78353927, 0.77009886, 0.75625365,
       0.74200365, 0.72734885, 0.71228925, 0.69682486, 0.68095567,
       0.66468169, 0.64800291, 0.63091933, 0.61343096, 0.59553779,
       0.57723982, 0.55853706, 0.5394295 , 0.51991715, 0.5       ]), 'alpha': array([9.99900000e-01, 9.99313127e-01, 9.97835484e-01, 9.95066307e-01,
       9.90611890e-01, 9.84091069e-01, 9.75142205e-01, 9.63431487e-01,
       9.48662327e-01, 9.30585521e-01, 9.09009761e-01, 8.83811975e-01,
       8.54946916e-01, 8.22455330e-01, 7.86470033e-01, 7.47219220e-01,
       7.05026403e-01, 6.60306493e-01, 6.13557725e-01, 5.65349358e-01,
       5.16305351e-01, 4.67084533e-01, 4.18358078e-01, 3.70785381e-01,
       3.24989637e-01, 2.81534572e-01, 2.40903787e-01, 2.03484051e-01,
       1.69553685e-01, 1.39276776e-01, 1.12703560e-01, 8.97768252e-02,
       7.03436678e-02, 5.41715780e-02, 4.09674536e-02, 3.03979999e-02,
       2.21099502e-02, 1.57486798e-02, 1.09740716e-02, 7.47285631e-03,
       4.96707074e-03, 3.21867628e-03, 2.03072508e-03, 1.24570963e-03,
       7.41867159e-04, 4.28235268e-04, 2.39185268e-04, 1.29023591e-04,
       6.70815775e-05, 3.35407888e-05]), 'alpha_torch': tensor([[[9.9990e-01]],

        [[9.9931e-01]],

        [[9.9784e-01]],

        [[9.9507e-01]],

        [[9.9061e-01]],

        [[9.8409e-01]],

        [[9.7514e-01]],

        [[9.6343e-01]],

        [[9.4866e-01]],

        [[9.3059e-01]],

        [[9.0901e-01]],

        [[8.8381e-01]],

        [[8.5495e-01]],

        [[8.2246e-01]],

        [[7.8647e-01]],

        [[7.4722e-01]],

        [[7.0503e-01]],

        [[6.6031e-01]],

        [[6.1356e-01]],

        [[5.6535e-01]],

        [[5.1631e-01]],

        [[4.6708e-01]],

        [[4.1836e-01]],

        [[3.7079e-01]],

        [[3.2499e-01]],

        [[2.8153e-01]],

        [[2.4090e-01]],

        [[2.0348e-01]],

        [[1.6955e-01]],

        [[1.3928e-01]],

        [[1.1270e-01]],

        [[8.9777e-02]],

        [[7.0344e-02]],

        [[5.4172e-02]],

        [[4.0967e-02]],

        [[3.0398e-02]],

        [[2.2110e-02]],

        [[1.5749e-02]],

        [[1.0974e-02]],

        [[7.4729e-03]],

        [[4.9671e-03]],

        [[3.2187e-03]],

        [[2.0307e-03]],

        [[1.2457e-03]],

        [[7.4187e-04]],

        [[4.2824e-04]],

        [[2.3919e-04]],

        [[1.2902e-04]],

        [[6.7082e-05]],

        [[3.3541e-05]]], device='cuda:0')}
02:25:45  training start with epochs:200,learning_rate:0.001
02:25:58  average loss:0.4010272216796875 at epoch:0
02:26:10  average loss:0.3245838492257255 at epoch:1
02:26:20  average loss:0.33056690761021207 at epoch:2
02:26:31  average loss:0.31912673950195314 at epoch:3
02:26:41  average loss:0.30698686872209824 at epoch:4
02:26:58  best loss:0.2617359132720874,epoch:4
02:27:09  average loss:0.2796478489467076 at epoch:5
02:27:20  average loss:0.28500948224748884 at epoch:6
02:27:31  average loss:0.2806044660295759 at epoch:7
02:27:43  average loss:0.2628776550292969 at epoch:8
02:27:54  average loss:0.27792225428989953 at epoch:9
02:28:13  best loss:0.23155240542613542,epoch:9
02:28:25  average loss:0.26666346958705356 at epoch:10
02:28:37  average loss:0.257872314453125 at epoch:11
02:28:49  average loss:0.2707090541294643 at epoch:12
02:29:00  average loss:0.2631707763671875 at epoch:13
02:29:12  average loss:0.25930483136858257 at epoch:14
02:29:31  best loss:0.214231204528075,epoch:14
02:29:42  average loss:0.25682972499302453 at epoch:15
02:29:54  average loss:0.2644336373465402 at epoch:16
02:30:05  average loss:0.2584319632393973 at epoch:17
02:30:16  average loss:0.25437329973493306 at epoch:18
02:30:27  average loss:0.24888946533203124 at epoch:19
02:30:47  best loss:0.20695514346544558,epoch:19
02:30:58  average loss:0.2705908203125 at epoch:20
02:31:09  average loss:0.24331200735909597 at epoch:21
02:31:20  average loss:0.26599151611328126 at epoch:22
02:31:31  average loss:0.25518203735351563 at epoch:23
02:31:42  average loss:0.2507542201450893 at epoch:24
02:32:12  average loss:0.24689215523856026 at epoch:25
02:32:24  average loss:0.22953802926199776 at epoch:26
02:32:35  average loss:0.24620982578822545 at epoch:27
02:32:47  average loss:0.25557591029575893 at epoch:28
02:32:59  average loss:0.2531947544642857 at epoch:29
02:33:17  best loss:0.20267902314662933,epoch:29
02:33:29  average loss:0.24291384015764508 at epoch:30
02:33:41  average loss:0.2512573460170201 at epoch:31
02:33:53  average loss:0.25187957763671875 at epoch:32
02:34:05  average loss:0.24485177176339284 at epoch:33
02:34:16  average loss:0.2526556614467076 at epoch:34
02:34:35  best loss:0.20254071400715754,epoch:34
02:34:46  average loss:0.2407376970563616 at epoch:35
02:34:57  average loss:0.24271150861467633 at epoch:36
02:35:09  average loss:0.2593267604282924 at epoch:37
02:35:21  average loss:0.24527003696986607 at epoch:38
02:35:32  average loss:0.25392857142857145 at epoch:39
02:35:51  best loss:0.20005440540038621,epoch:39
02:36:03  average loss:0.2422598920549665 at epoch:40
02:36:15  average loss:0.24637619018554688 at epoch:41
02:36:27  average loss:0.24212243216378349 at epoch:42
02:36:40  average loss:0.2423026384626116 at epoch:43
02:36:52  average loss:0.2437288774762835 at epoch:44
02:37:11  best loss:0.19863082411197516,epoch:44
02:37:22  average loss:0.25819344656808035 at epoch:45
02:37:34  average loss:0.2301234872000558 at epoch:46
02:37:46  average loss:0.24600234985351563 at epoch:47
02:37:58  average loss:0.23493565150669643 at epoch:48
02:38:10  average loss:0.2425993129185268 at epoch:49
02:38:28  best loss:0.19304551298801714,epoch:49
02:38:40  average loss:0.24120339529854912 at epoch:50
02:38:51  average loss:0.24007356916155134 at epoch:51
02:39:03  average loss:0.24773659842354911 at epoch:52
02:39:15  average loss:0.2387194606236049 at epoch:53
02:39:27  average loss:0.2442946297781808 at epoch:54
02:39:57  average loss:0.23816170828683036 at epoch:55
02:40:09  average loss:0.24249210902622767 at epoch:56
02:40:21  average loss:0.24975182669503349 at epoch:57
02:40:32  average loss:0.2358128138950893 at epoch:58
02:40:44  average loss:0.2292980739048549 at epoch:59
02:41:03  best loss:0.19152362358111602,epoch:59
02:41:15  average loss:0.23860948835100446 at epoch:60
02:41:27  average loss:0.24329232352120536 at epoch:61
02:41:39  average loss:0.23092019217354912 at epoch:62
02:41:51  average loss:0.2345627702985491 at epoch:63
02:42:02  average loss:0.23413253784179688 at epoch:64
02:42:32  average loss:0.230489262172154 at epoch:65
02:42:45  average loss:0.2351493617466518 at epoch:66
02:42:56  average loss:0.23782071794782367 at epoch:67
02:43:08  average loss:0.2365065656389509 at epoch:68
02:43:19  average loss:0.23691068376813615 at epoch:69
02:43:49  average loss:0.24063195364815848 at epoch:70
02:44:01  average loss:0.23285343715122767 at epoch:71
02:44:12  average loss:0.24160838535853796 at epoch:72
02:44:23  average loss:0.23954827444893972 at epoch:73
02:44:35  average loss:0.24126815795898438 at epoch:74
02:44:54  best loss:0.1883201077580452,epoch:74
02:45:06  average loss:0.22977220807756696 at epoch:75
02:45:18  average loss:0.22918267386300223 at epoch:76
02:45:30  average loss:0.2366158185686384 at epoch:77
02:45:41  average loss:0.24360039847237724 at epoch:78
02:45:53  average loss:0.23824225289481027 at epoch:79
02:46:24  average loss:0.24097974504743302 at epoch:80
02:46:36  average loss:0.23119007655552457 at epoch:81
02:46:48  average loss:0.23700291224888392 at epoch:82
02:46:59  average loss:0.23559228079659597 at epoch:83
02:47:11  average loss:0.23372301374162946 at epoch:84
02:47:42  average loss:0.23054556710379465 at epoch:85
02:47:53  average loss:0.22822405133928572 at epoch:86
02:48:05  average loss:0.2373677498953683 at epoch:87
02:48:17  average loss:0.24311678205217635 at epoch:88
02:48:29  average loss:0.23111168997628348 at epoch:89
02:49:00  average loss:0.23435073852539062 at epoch:90
02:49:12  average loss:0.22466884068080356 at epoch:91
02:49:24  average loss:0.23307449340820313 at epoch:92
02:49:36  average loss:0.24464287894112724 at epoch:93
02:49:48  average loss:0.236119624546596 at epoch:94
02:50:18  average loss:0.23776194981166296 at epoch:95
02:50:29  average loss:0.2250040544782366 at epoch:96
02:50:40  average loss:0.2350832039969308 at epoch:97
02:50:52  average loss:0.2217580086844308 at epoch:98
02:51:04  average loss:0.2318678937639509 at epoch:99
02:51:36  average loss:0.22831950596400669 at epoch:100
02:51:48  average loss:0.22866544451032367 at epoch:101
02:51:59  average loss:0.22962188720703125 at epoch:102
02:52:11  average loss:0.24309156145368305 at epoch:103
02:52:23  average loss:0.22951738630022323 at epoch:104
02:52:54  average loss:0.22949986049107143 at epoch:105
02:53:05  average loss:0.24713638305664062 at epoch:106
02:53:17  average loss:0.2263014657156808 at epoch:107
02:53:29  average loss:0.22978707449776786 at epoch:108
02:53:41  average loss:0.23393319266183035 at epoch:109
02:54:00  best loss:0.18718971541294685,epoch:109
02:54:12  average loss:0.23335364205496653 at epoch:110
02:54:23  average loss:0.23788286481584822 at epoch:111
02:54:35  average loss:0.2288515363420759 at epoch:112
02:54:48  average loss:0.23480919974190848 at epoch:113
02:54:59  average loss:0.23411956787109375 at epoch:114
02:55:30  average loss:0.2305424281529018 at epoch:115
02:55:42  average loss:0.23023241315569196 at epoch:116
02:55:55  average loss:0.241767578125 at epoch:117
02:56:07  average loss:0.23542875017438616 at epoch:118
02:56:18  average loss:0.2422652544294085 at epoch:119
02:56:37  best loss:0.1864864883514551,epoch:119
02:56:49  average loss:0.2400658961704799 at epoch:120
02:57:00  average loss:0.22548915318080356 at epoch:121
02:57:12  average loss:0.2239170183454241 at epoch:122
02:57:24  average loss:0.22133383614676339 at epoch:123
02:57:35  average loss:0.23474805559430803 at epoch:124
02:57:54  best loss:0.18497009575366974,epoch:124
02:58:06  average loss:0.22208110264369418 at epoch:125
02:58:18  average loss:0.23932909284319195 at epoch:126
02:58:29  average loss:0.22658309936523438 at epoch:127
02:58:41  average loss:0.22028010777064733 at epoch:128
02:58:53  average loss:0.23927442278180805 at epoch:129
02:59:11  best loss:0.18495156386723885,epoch:129
02:59:23  average loss:0.2288287135532924 at epoch:130
02:59:35  average loss:0.23317452566964286 at epoch:131
02:59:46  average loss:0.23213878086635045 at epoch:132
02:59:58  average loss:0.2396830749511719 at epoch:133
03:00:10  average loss:0.22491973876953125 at epoch:134
03:00:40  average loss:0.23710231236049106 at epoch:135
03:00:52  average loss:0.2338085719517299 at epoch:136
03:01:04  average loss:0.22844188145228794 at epoch:137
03:01:15  average loss:0.23177150181361608 at epoch:138
03:01:27  average loss:0.2319138445172991 at epoch:139
03:01:56  average loss:0.23298758370535713 at epoch:140
03:02:07  average loss:0.23131539481026786 at epoch:141
03:02:19  average loss:0.23463954380580357 at epoch:142
03:02:30  average loss:0.22949872698102677 at epoch:143
03:02:42  average loss:0.2311332266671317 at epoch:144
03:03:13  average loss:0.22743251255580357 at epoch:145
03:03:24  average loss:0.2186586434500558 at epoch:146
03:03:36  average loss:0.2330695016043527 at epoch:147
03:03:47  average loss:0.23124476841517858 at epoch:148
03:03:58  average loss:0.2287164306640625 at epoch:149
03:04:17  best loss:0.18352026205796462,epoch:149
03:04:29  average loss:0.2283248247419085 at epoch:150
03:04:40  average loss:0.22227044241768973 at epoch:151
03:04:52  average loss:0.22168249947684152 at epoch:152
03:05:03  average loss:0.24205625261579242 at epoch:153
03:05:15  average loss:0.21791427612304687 at epoch:154
03:05:34  best loss:0.1762408591233767,epoch:154
03:05:45  average loss:0.22353724888392856 at epoch:155
03:05:57  average loss:0.21701649257114955 at epoch:156
03:06:08  average loss:0.22757829938616073 at epoch:157
03:06:20  average loss:0.22149466378348215 at epoch:158
03:06:31  average loss:0.21734058925083705 at epoch:159
03:07:02  average loss:0.23054896763392857 at epoch:160
03:07:14  average loss:0.22970511300223215 at epoch:161
03:07:26  average loss:0.2126347133091518 at epoch:162
03:07:37  average loss:0.22420841761997767 at epoch:163
03:07:49  average loss:0.22957098824637276 at epoch:164
03:08:08  best loss:0.17522501544310495,epoch:164
03:08:19  average loss:0.22182767595563616 at epoch:165
03:08:30  average loss:0.21849984305245534 at epoch:166
03:08:42  average loss:0.22437369210379465 at epoch:167
03:08:54  average loss:0.22866644723074778 at epoch:168
03:09:05  average loss:0.22758492606026787 at epoch:169
03:09:36  average loss:0.21846208844866072 at epoch:170
03:09:47  average loss:0.2197267586844308 at epoch:171
03:09:59  average loss:0.21994086129324777 at epoch:172
03:10:11  average loss:0.22143441336495537 at epoch:173
03:10:22  average loss:0.233521968296596 at epoch:174
03:10:41  best loss:0.17461865223371065,epoch:174
03:10:53  average loss:0.21132627214704242 at epoch:175
03:11:05  average loss:0.21934960501534598 at epoch:176
03:11:16  average loss:0.22467917306082588 at epoch:177
03:11:27  average loss:0.2140423148018973 at epoch:178
03:11:39  average loss:0.21658556256975448 at epoch:179
03:11:58  best loss:0.17449894375525987,epoch:179
03:12:09  average loss:0.22653812953404018 at epoch:180
03:12:21  average loss:0.2175508989606585 at epoch:181
03:12:32  average loss:0.2254502214704241 at epoch:182
03:12:43  average loss:0.23328255789620536 at epoch:183
03:12:55  average loss:0.22541976928710938 at epoch:184
03:13:25  average loss:0.22355900355747768 at epoch:185
03:13:37  average loss:0.2158119637625558 at epoch:186
03:13:49  average loss:0.2343481663295201 at epoch:187
03:14:00  average loss:0.22970668247767856 at epoch:188
03:14:11  average loss:0.21927117483956474 at epoch:189
03:14:42  average loss:0.22319329398018972 at epoch:190
03:14:54  average loss:0.22051079886300223 at epoch:191
03:15:05  average loss:0.21643223353794644 at epoch:192
03:15:18  average loss:0.21877354213169642 at epoch:193
03:15:29  average loss:0.21993929181780134 at epoch:194
03:15:48  best loss:0.17414242258438697,epoch:194
03:16:00  average loss:0.21968416486467635 at epoch:195
03:16:11  average loss:0.21383084978376116 at epoch:196
03:16:23  average loss:0.22531090872628348 at epoch:197
03:16:35  average loss:0.2208788844517299 at epoch:198
03:16:46  average loss:0.2252080862862723 at epoch:199
03:17:05  best loss:0.17092390816945296,epoch:199
03:17:05  training completed with best_valid_loss:4.444021612405777
03:17:05  evaluation start with nsample:100
03:18:17  Batch_no:1:MSE:74.47183990478516,MAE:94.64766693115234
03:19:28  Batch_no:2:MSE:74.94900512695312,MAE:114.01800537109375
03:20:38  Batch_no:3:MSE:125.11846923828125,MAE:98.40151977539062
03:21:49  Batch_no:4:MSE:156.8599395751953,MAE:116.2261734008789
03:23:00  Batch_no:5:MSE:182.8064727783203,MAE:128.86740112304688
03:24:11  Batch_no:6:MSE:90.26324462890625,MAE:100.40771484375
03:25:22  Batch_no:7:MSE:91.47029876708984,MAE:116.52273559570312
03:26:33  Batch_no:8:MSE:279.30029296875,MAE:116.41047668457031
03:27:44  Batch_no:9:MSE:251.44747924804688,MAE:124.6815185546875
03:28:55  Batch_no:10:MSE:105.252197265625,MAE:120.45138549804688
03:30:06  Batch_no:11:MSE:51.48286437988281,MAE:93.6414794921875
03:31:16  Batch_no:12:MSE:108.49003601074219,MAE:125.98052215576172
03:32:27  Batch_no:13:MSE:279.47015380859375,MAE:133.0846710205078
03:33:38  Batch_no:14:MSE:323.4744873046875,MAE:120.94236755371094
03:34:49  Batch_no:15:MSE:147.21841430664062,MAE:135.52621459960938
03:36:00  Batch_no:16:MSE:97.94926452636719,MAE:123.280517578125
03:37:11  Batch_no:17:MSE:73.06520080566406,MAE:102.54344940185547
03:38:22  Batch_no:18:MSE:207.83282470703125,MAE:105.41931915283203
03:39:33  Batch_no:19:MSE:91.4291763305664,MAE:119.79816436767578
03:40:44  Batch_no:20:MSE:62.3660774230957,MAE:89.8199462890625
03:41:55  Batch_no:21:MSE:129.27590942382812,MAE:126.18391418457031
03:43:06  Batch_no:22:MSE:89.54055786132812,MAE:114.74806213378906
03:44:16  Batch_no:23:MSE:77.68264770507812,MAE:103.64208221435547
03:45:27  Batch_no:24:MSE:146.07492065429688,MAE:137.0493927001953
03:46:38  Batch_no:25:MSE:95.9298324584961,MAE:111.56451416015625
03:47:49  Batch_no:26:MSE:86.4095458984375,MAE:100.01795959472656
03:48:59  Batch_no:27:MSE:198.83087158203125,MAE:120.79335021972656
03:50:10  Batch_no:28:MSE:104.70111846923828,MAE:103.4021224975586
03:51:21  Batch_no:29:MSE:110.90563201904297,MAE:127.1512222290039
03:52:32  Batch_no:30:MSE:99.83161926269531,MAE:101.16211700439453
03:53:42  Batch_no:31:MSE:88.30059051513672,MAE:106.50928497314453
03:54:53  Batch_no:32:MSE:165.6978302001953,MAE:114.39505004882812
03:56:04  Batch_no:33:MSE:70.32366180419922,MAE:111.27937316894531
03:57:15  Batch_no:34:MSE:100.67070770263672,MAE:110.90350341796875
03:58:25  Batch_no:35:MSE:57.55708312988281,MAE:99.8258056640625
03:59:36  Batch_no:36:MSE:207.10919189453125,MAE:130.12216186523438
04:00:47  Batch_no:37:MSE:184.83245849609375,MAE:133.1282958984375
04:01:58  Batch_no:38:MSE:119.46492767333984,MAE:120.13299560546875
04:03:09  Batch_no:39:MSE:108.09911346435547,MAE:111.96800231933594
04:04:20  Batch_no:40:MSE:108.09517669677734,MAE:103.26316833496094
04:05:31  Batch_no:41:MSE:427.35784912109375,MAE:148.1185302734375
04:06:42  Batch_no:42:MSE:128.23841857910156,MAE:125.01258087158203
04:07:53  Batch_no:43:MSE:67.54742431640625,MAE:103.72100830078125
04:09:04  Batch_no:44:MSE:386.92840576171875,MAE:122.1693115234375
04:10:15  Batch_no:45:MSE:68.8442153930664,MAE:108.07295227050781
04:11:26  Batch_no:46:MSE:62.10331344604492,MAE:97.66221618652344
04:12:37  Batch_no:47:MSE:88.76170349121094,MAE:104.83067321777344
04:13:48  Batch_no:48:MSE:173.82562255859375,MAE:116.27064514160156
04:14:59  Batch_no:49:MSE:98.85790252685547,MAE:122.2552490234375
04:16:05  Batch_no:50:MSE:68.26825714111328,MAE:91.77692413330078
04:16:10  RMSE:0.5128817266503115
04:16:10  MAE:0.2209671990463743
04:16:10  CRPS:0.24332977596082186
